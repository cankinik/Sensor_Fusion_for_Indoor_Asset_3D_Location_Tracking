{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac01810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import cv2 as cv\n",
    "import os\n",
    "import glob\n",
    "import pyzbar\n",
    "from __future__ import print_function\n",
    "import pyzbar.pyzbar as pyzbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b3dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch Out! square_size is tunable and depend on the chessboard image, I am not exactly sure about this particular value, \n",
    "# but all that it changes is scale, so if things look correct, but the dimensions seem too low/big, then this is a good suspect\n",
    "square_size = 0.027 \n",
    "\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# Horizontal and vertical are flipped, but lazy. The numbers must be exact, and they are the corners inside, not outside\n",
    "horizontal = 7 \n",
    "vertical = 4\n",
    "objp = np.zeros((horizontal*vertical,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:horizontal,0:vertical].T.reshape(-1,2) * square_size\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "images = glob.glob('Calibration_Images/*.png')\n",
    "for fname in images:\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (horizontal,vertical), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(img, (horizontal,vertical), corners2, ret)\n",
    "        cv.imshow('img', img)\n",
    "        cv.waitKey(200)\n",
    "cv.destroyAllWindows()\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, mtx, (1280,720), cv2.CV_32FC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72709ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted correcting features for the anchor\n"
     ]
    }
   ],
   "source": [
    "square_size = 0.054\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# Horizontal and vertical are flipped, but lazy. The numbers must be exact, and they are the corners inside, not outside\n",
    "# Watch Out! The fact that these are flipped may have something to do with the switching column business\n",
    "horizontal = 4 \n",
    "vertical = 7\n",
    "objp = np.zeros((horizontal*vertical,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:horizontal,0:vertical].T.reshape(-1,2) * square_size\n",
    "\n",
    "img = cv.imread('Anchor_1_checkerboard_image.png')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "# Find the chess board corners\n",
    "ret, corners = cv.findChessboardCorners(gray, (horizontal,vertical), None)\n",
    "# If found, add object points, image points (after refining them)\n",
    "if ret == True:\n",
    "    ret, rvecs, tvecs = cv.solvePnP(objp, corners, mtx, dist)\n",
    "    correcting_rotation_matrix, _ = cv2.Rodrigues(rvecs)\n",
    "    correcting_translation_vector = tvecs.T\n",
    "    print('Extracted correcting features for the anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af0cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_coordinate_system(x, y, z):\n",
    "    x -= correcting_translation_vector[0, 0]\n",
    "    y -= correcting_translation_vector[0, 1]\n",
    "    z -= correcting_translation_vector[0, 2]\n",
    "    row1 = x * correcting_rotation_matrix[0, 0] + y * correcting_rotation_matrix[1, 0] + z * correcting_rotation_matrix[2, 0]\n",
    "    row2 = x * correcting_rotation_matrix[0, 1] + y * correcting_rotation_matrix[1, 1] + z * correcting_rotation_matrix[2, 1]\n",
    "    row3 = x * correcting_rotation_matrix[0, 2] + y * correcting_rotation_matrix[1, 2] + z * correcting_rotation_matrix[2, 2]\n",
    "    shiftingX = correcting_translation_vector[0, 0] * correcting_rotation_matrix[0, 0] + correcting_translation_vector[0, 1] * correcting_rotation_matrix[0, 1] + correcting_translation_vector[0, 2] * correcting_rotation_matrix[0, 2]\n",
    "    shiftingY = correcting_translation_vector[0, 0] * correcting_rotation_matrix[1, 0] + correcting_translation_vector[0, 1] * correcting_rotation_matrix[1, 1] + correcting_translation_vector[0, 2] * correcting_rotation_matrix[1, 2]\n",
    "    shiftingZ = correcting_translation_vector[0, 0] * correcting_rotation_matrix[2, 0] + correcting_translation_vector[0, 1] * correcting_rotation_matrix[2, 1] + correcting_translation_vector[0, 2] * correcting_rotation_matrix[2, 2]\n",
    "    x = row1 #+ shiftingX\n",
    "    y = row2 #+ shiftingY\n",
    "    z = row3\n",
    "    return np.array([x, y, z]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cceda038",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrDecoder = cv2.QRCodeDetector()\n",
    "cam = cv2.VideoCapture('Anchor_1_video.mp4') \n",
    "cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "objp = np.zeros((2*2,3), np.float32)   # The order is top left, top right, bottom left, bottom right. img points must match\n",
    "objp[:,:2] = np.mgrid[0:2,0:2].T.reshape(-1,2) * 0.4   # Tune this value by checking with IRL measurements, was 0.245 for A4, 0.4 for our QR code\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"End of Video/Coudln't grab frames\")\n",
    "        break\n",
    "    frame = cv2.remap(frame, mapx, mapy, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)\n",
    " \n",
    "    decodedObjects = pyzbar.decode(frame)\n",
    "    for idx, decodedObject in enumerate(decodedObjects):\n",
    "        points = decodedObject.polygon\n",
    "        for j in range(4):\n",
    "            cv2.line(frame, points[j], points[((j+1)%4)], (255,0,0), 3)\n",
    "        points = np.array(decodedObject.polygon, dtype=int)\n",
    "#         temp = [[[points[0, 0], points[0, 1]]], [[points[3, 0], points[3, 1]]], [[points[1, 0], points[1, 1]]], [[points[2, 0], points[2, 1]]]]\n",
    "#         temp = np.array(temp, dtype=np.float32)\n",
    "#         ret,rvecs, tvecs = cv.solvePnP(objp, temp, mtx, dist)\n",
    "#         # Watch Out! While testing on my own, I realized that there was something weird, where moving back and forth changed \n",
    "#         # the x and y measurement, even though you would expect it to not when only the distance is changing, so I divided it \n",
    "#         # by the z value and that kept it constant. However, this also doesn't seem right, and perhaps it is just supposed to do\n",
    "#         # that due to the way egocentric coordinates work.\n",
    "#         x = tvecs[0] #/ tvecs[2]   \n",
    "#         y = tvecs[1] #/ tvecs[2]\n",
    "#         z = tvecs[2]\n",
    "        x = 0\n",
    "        y = 0\n",
    "        z = 0\n",
    "        for i in range(4):        \n",
    "            temp = [[[points[(0 + i)%4, 0], points[(0 + i)%4, 1]]], [[points[(3 + i)%4, 0], points[(3 + i)%4, 1]]], [[points[(1 + i)%4, 0], points[(1 + i)%4, 1]]], [[points[(2 + i)%4, 0], points[(2 + i)%4, 1]]]]\n",
    "            temp = np.array(temp, dtype=np.float32)\n",
    "            ret,rvecs, tvecs = cv.solvePnP(objp, temp, mtx, dist)\n",
    "            x += tvecs[0]/4\n",
    "            y += tvecs[1]/4\n",
    "            z += tvecs[2]/4\n",
    "        # If you run this line instead of the bootom one, it will display the egocentric coordinates on the video feed\n",
    "#         cv2.putText(frame, str(tvecs) + ' Data: ' + (decodedObject.data).decode('utf-8'), (20, (i + 1) * 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
    "        # Watch Out! This is the function that you need to implement to align the data\n",
    "        global_coordinates = change_coordinate_system(x, y, z)\n",
    "        cv2.putText(frame, str(global_coordinates) + ' Data: ' + (decodedObject.data).decode('utf-8'), (20, (idx + 1) * 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
    "    \n",
    "    \n",
    "    frame = cv2.resize(frame, (1280, 720))\n",
    "    cv2.imshow(\"output\", frame)   \n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:   # Stops when ESC is entered\n",
    "        break\n",
    "    elif k%256 == 32: # Spacebar to skip a few frames\n",
    "        for i in range(200):\n",
    "            cam.read()\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e71d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
